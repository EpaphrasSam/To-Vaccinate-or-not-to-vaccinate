{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d04fbeb8",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d04fbeb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from simpletransformers.classification.classification_model import ClassificationModel\n",
        "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11f949f3",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "11f949f3"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('./Train.csv')\n",
        "# train_df = train_df.drop(['agreement'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c04b990c",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c04b990c",
        "outputId": "2e8ac35f-0e92-4139-fd8b-d9180d3ca23e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tweet_id     0\n",
              "safe_text    0\n",
              "label        0\n",
              "agreement    2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.loc[~train_df['label'].isin([0, -1, 1]), 'label'] = -1\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b65c3878",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b65c3878",
        "outputId": "25aa0131-d131-40e6-b3c4-6cdf8239f0b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tweet_id     0\n",
              "safe_text    0\n",
              "label        0\n",
              "agreement    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df.dropna()\n",
        "train_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2d7ad5ee",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2d7ad5ee"
      },
      "outputs": [],
      "source": [
        "trains_df, evals_df = train_test_split(train_df, test_size=0.2, random_state=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d1b474f",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6d1b474f"
      },
      "outputs": [],
      "source": [
        "train_data = trains_df[['safe_text', 'label']]\n",
        "eval_data = evals_df[['safe_text', 'label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "589442ef",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = ClassificationModel('roberta', 'roberta-large', num_labels=1, args={\n",
        "            'train_batch_size': 16,\n",
        "            'eval_batch_size': 16,\n",
        "            'reprocess_input_data': True,\n",
        "            'overwrite_output_dir': True,\n",
        "            'fp16': True,\n",
        "            'do_lower_case': False,\n",
        "            'num_train_epochs': 3,\n",
        "            'max_seq_length': 236,\n",
        "            'regression': True,\n",
        "            'manual_seed': 2,\n",
        "            'learning_rate': 1e-5,\n",
        "            'save_eval_checkpoints': False,\n",
        "            'save_model_every_epoch': False,\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "-NndSY9xhl_I",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-NndSY9xhl_I"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\anaconda3\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5462360081ec4558b4f743f9232da4ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7999 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.train_model(train_data)\n",
        "preds_val = model.eval_model(eval_data)[1]\n",
        "preds_val = np.clip(preds_val, -1, 1)\n",
        "print(f\"RMSE: {mse(eval_data['label'], preds_val)**0.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uWi7DUODF1ko",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uWi7DUODF1ko"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('./Test.csv')\n",
        "test_df['safe_text'] = test_df['safe_text'].fillna('xxxxxx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qhWGi2RufVUn",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qhWGi2RufVUn"
      },
      "outputs": [],
      "source": [
        "tmp_test = test_df[['safe_text']]\n",
        "tmp_test['labels'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tRZ9vBBrflQq",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tRZ9vBBrflQq"
      },
      "outputs": [],
      "source": [
        "test_preds = model.eval_model(tmp_test)[1]\n",
        "test_preds = np.clip(test_preds, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4zfEgYisrczm",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4zfEgYisrczm"
      },
      "outputs": [],
      "source": [
        "test_preds_df = pd.DataFrame({'id': test_df['tweet_id'], 'label': test_preds})\n",
        "\n",
        "test_preds_df.to_csv('Submission1.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Di94w3yYvBcK",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Di94w3yYvBcK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "gpu2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
